{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Harmonize HBN data using ComBat\n\nThis example loads AFQ data from the Healthy Brain Network (HBN) preprocessed\ndiffusion derivatives [1]_. The HBN is a landmark pediatric mental health study.\nOver the course of the study, it will collect diffusion MRI data from\napproximately 5,000 children and adolescents. We recently processed the\navailable data from over 2,000 of these subjects, and provide the tract profiles\nfrom this dataset, which can be downloaded from AWS thanks to\n[INDI](http://fcon_1000.projects.nitrc.org/).\n\nWe first load the data by using the :func:`AFQDataset.from_files` static method\nand supplying AWS S3 URIs instead of local file names. We then impute missing\nvalues and plot the mean bundle profiles by scanning site, noting that there are\nsubstantial site differences. Lastly, we harmonize the site differences using\nNeuroComBat [2]_ and plot the harmonized bundle profiles to verify that the site\ndifferences have been removed.\n\n.. [1]  Adam Richie-Halford, Matthew Cieslak, Lei Ai, Sendy Caffarra, Sydney\n   Covitz, Alexandre R. Franco, Iliana I. Karipidis, John Kruper, Michael\n   Milham, B\u00e1rbara Avelar-Pereira, Ethan Roy, Valerie J. Sydnor, Jason Yeatman,\n   The Fibr Community Science Consortium, Theodore D. Satterthwaite, and Ariel\n   Rokem,\n   \"An open, analysis-ready, and quality controlled resource for pediatric brain\n   white-matter research\"\n   bioRxiv 2022.02.24.481303;\n   doi: https://doi.org/10.1101/2022.02.24.481303\n\n.. [2] Jean-Philippe Fortin, Drew Parker, Birkan Tunc, Takanori Watanabe, Mark A\n   Elliott, Kosha Ruparel, David R Roalf, Theodore D Satterthwaite, Ruben C Gur,\n   Raquel E Gur, Robert T Schultz, Ragini Verma, Russell T Shinohara.\n   \"Harmonization Of Multi-Site Diffusion Tensor Imaging Data\"\n   NeuroImage, 161, 149-170, 2017;\n   doi: https://doi.org/10.1016/j.neuroimage.2017.08.047\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom afqinsight import AFQDataset\nfrom afqinsight.plot import plot_tract_profiles\nfrom neurocombat_sklearn import CombatModel\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch the HBN data\n\nThe :func:`AFQDataset.from_files` static method expects a path to\nnodes.csv and subjects.csv files, but these file paths can be remote\nURLs or AWS S3 URIs. We'll use S3 URIs to grab the HBN data. After dropping\nparticipants with null phenotypic values, it has 1,867 participants.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = AFQDataset.from_files(\n    fn_nodes=\"s3://fcp-indi/data/Projects/HBN/BIDS_curated/derivatives/afq/combined_tract_profiles.csv\",\n    fn_subjects=\"s3://fcp-indi/data/Projects/HBN/BIDS_curated/derivatives/qsiprep/participants.tsv\",\n    dwi_metrics=[\"dki_fa\", \"dki_md\"],\n    target_cols=[\"age\", \"sex\", \"scan_site_id\"],\n    label_encode_cols=[\"sex\", \"scan_site_id\"],\n    index_col=\"subject_id\",\n)\ndataset.drop_target_na()\nprint(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train / test split\n\nWe can use the dataset in the :func:`train_test_split` function just as we\nwould with an array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_train, dataset_test = train_test_split(dataset, test_size=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Impute missing values\n\nNext we impute missing values using median imputation. We fit the imputer\nusing the training set and then use it to transform both the training and test\nsets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imputer = dataset_train.model_fit(SimpleImputer(strategy=\"median\"))\ndataset_train = dataset_train.model_transform(imputer)\ndataset_test = dataset_test.model_transform(imputer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot average bundle profiles by scan site\n\nNext we plot the mean bundle profiles in the test set by scanning site. The\n:func:`plot_tract_profiles` function takes as input an :class:`AFQDataset` and\nreturns matplotlib figures displaying the mean bundle profile for each bundle\nand metric, optionally grouped by a categorical or continuous variable.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "site_figs = plot_tract_profiles(\n    X=dataset_test,\n    group_by=dataset_test.classes[\"scan_site_id\"][dataset_test.y[:, 2].astype(int)],\n    group_by_name=\"Site\",\n    figsize=(14, 14),\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Harmonize the sites and replot\n\nWe can see that there are substantial scan site differences in both the\nFA and MD profiles. Let's use neuroComBat to harmonize the site differences\nand then replot the mean bundle profiles.\n\nN.B. We use the excellent [neurocombat_sklearn](https://github.com/Warvito/neurocombat_sklearn) package to apply ComBat to\nour data. We love this library, however it is not fully compliant with the\nscikit-learn transformer API, so we cannot use the\n:func:`AFQDataset.model_fit_transform` method to apply this transformer to our\ndataset. No problem! We can simply copy the unharmonized dataset into a new\nvariable and then overwrite the features of the new dataset with the ComBat\noutput.\n\nLastly, we replot the mean bundle profiles and confirm that ComBat did its\njob.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Fit the ComBat transformer to the training set\ncombat = CombatModel()\ncombat.fit(\n    dataset_train.X,\n    dataset_train.y[:, 2][:, np.newaxis],\n    dataset_train.y[:, 1][:, np.newaxis],\n    dataset_train.y[:, 0][:, np.newaxis],\n)\n\n# And then transform a copy of the test set\nharmonized_test = dataset_test.copy()\nharmonized_test.X = combat.transform(\n    dataset_test.X,\n    dataset_test.y[:, 2][:, np.newaxis],\n    dataset_test.y[:, 1][:, np.newaxis],\n    dataset_test.y[:, 0][:, np.newaxis],\n)\n\nsite_figs = plot_tract_profiles(\n    X=harmonized_test,\n    group_by=harmonized_test.classes[\"scan_site_id\"][\n        harmonized_test.y[:, 2].astype(int)\n    ],\n    group_by_name=\"Site\",\n    figsize=(14, 14),\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}