{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Classify ALS diagnosis from white matter features\n\nPredict ALS diagnosis from white matter features. This example fetches the ALS\nclassification dataset from Sarica et al [1]_. This dataset contains tractometry\nfeatures from 24 patients with ALS and 24 demographically matched control\nsubjects. The plots display the absolute value of the mean regression\ncoefficients (averaged across cross-validation splits) for the fractional\nanisotropy (FA) features.\n\nTo save computational time, we take the first 10 principal components from each\nfeature group (i.e. from each metric-bundle combination).\nFor more details on this approach in a research setting, please see [2]_.\n\n.. [1]  Alessia Sarica, et al.\n   \"The Corticospinal Tract Profile in AmyotrophicLateral Sclerosis\"\n   Human Brain Mapping, vol. 38, pp. 727-739, 2017\n   DOI: 10.1002/hbm.23412\n\n.. [2]  Adam Richie-Halford, Jason Yeatman, Noah Simon, and Ariel Rokem\n   \"Multidimensional analysis and detection of informative features in human brain white matter\"\n   PLOS Computational Biology, 2021\n   DOI: 10.1371/journal.pcbi.1009136\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport os.path as op\n\nfrom afqinsight.datasets import download_sarica, load_afq_data\nfrom afqinsight import make_afq_classifier_pipeline\n\nfrom groupyr.decomposition import GroupPCA\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_validate\n\nworkdir = download_sarica()\n\nafqdata = load_afq_data(\n    fn_nodes=op.join(workdir, \"nodes.csv\"),\n    fn_subjects=op.join(workdir, \"subjects.csv\"),\n    dwi_metrics=[\"md\", \"fa\"],\n    target_cols=[\"class\"],\n    label_encode_cols=[\"class\"],\n)\n\n# afqdata is a namedtuple. You can access it's fields using dot notation or by\n# unpacking the tuple. To see all of the available fields use `afqdata._fields`\nX = afqdata.X\ny = afqdata.y\ngroups = afqdata.groups\nfeature_names = afqdata.feature_names\ngroup_names = afqdata.group_names\nsubjects = afqdata.subjects\n\n# Here we reduce computation time by taking the first 10 principal components of each feature group and performing SGL logistic regression on those components.\n# If you want to train an SGL model without group PCA, set ``do_group_pca = False``. This will increase the number of features by an order of magnitude and slow down execution time.\ndo_group_pca = True\n\nif do_group_pca:\n    n_components = 10\n\n    # The next three lines retrieve the group structure of the group-wise PCA\n    # and store it in ``groups_pca``. We do not use the imputer or GroupPCA transformer\n    # for anything else\n    imputer = SimpleImputer(strategy=\"median\")\n    gpca = GroupPCA(n_components=n_components, groups=groups)\n    groups_pca = gpca.fit(imputer.fit_transform(X)).groups_out_\n\n    transformer = GroupPCA\n    transformer_kwargs = {\"groups\": groups, \"n_components\": n_components}\nelse:\n    transformer = False\n    transformer_kwargs = None\n\npipe = make_afq_classifier_pipeline(\n    imputer_kwargs={\"strategy\": \"median\"},  # Use median imputation\n    use_cv_estimator=True,  # Automatically determine the best hyperparameters\n    feature_transformer=transformer,  # See note above about group PCA\n    feature_transformer_kwargs=transformer_kwargs,\n    scaler=\"standard\",  # Standard scale the features before regression\n    groups=groups_pca\n    if do_group_pca\n    else groups,  # SGL will use the original feature groups or the PCA feature groups depending on the choice above\n    verbose=0,  # Be quiet!\n    pipeline_verbosity=False,  # No really, be quiet!\n    tuning_strategy=\"bayes\",  # Use BayesSearchCV to determine the optimal hyperparameters\n    n_bayes_iter=20,  # Consider only this many points in hyperparameter space\n    cv=3,  # Use three CV splits to evaluate each hyperparameter combination\n    l1_ratio=[0.0, 1.0],  # Explore the entire range of ``l1_ratio``\n    eps=5e-2,  # This is the ratio of the smallest to largest ``alpha`` value\n    tol=1e-2,  # Set a lenient convergence tolerance just for this example\n)\n\n# ``pipe`` is a scikit-learn pipeline and can be used in other scikit-learn functions\nscores = cross_validate(\n    pipe, X, y, cv=5, return_train_score=True, return_estimator=True\n)\n\nprint(f\"Mean train score: {np.mean(scores['train_score']):5.3f}\")\nprint(f\"Mean test score:  {np.mean(scores['test_score']):5.3f}\")\nprint(f\"Mean fit time:    {np.mean(scores['fit_time']):5.2f}s\")\nprint(f\"Mean score time:  {np.mean(scores['score_time']):5.2f}s\")\n\nmean_coefs = np.mean(\n    np.abs([est.named_steps[\"estimate\"].coef_ for est in scores[\"estimator\"]]), axis=0\n)\n\nfig, ax = plt.subplots(1, 1, figsize=(8, 5))\n_ = ax.plot(mean_coefs[:180], color=\"black\", lw=2)\n_ = ax.set_xlim(0, 180)\n\ncolors = plt.get_cmap(\"tab20\").colors\nfor grp, grp_name, color in zip(groups_pca[:18], group_names, colors):\n    _ = ax.axvspan(grp.min(), grp.max() + 1, color=color, alpha=0.8, label=grp_name[1])\n\nbox = ax.get_position()\n_ = ax.set_position(\n    [box.x0, box.y0 + box.height * 0.375, box.width, box.height * 0.625]\n)\n\n_ = ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.2), ncol=3)\n_ = ax.set_ylabel(r\"$\\hat{\\beta}$\", fontsize=16)\n_ = ax.set_xlabel(\"Group principal component\", fontsize=16)\n_ = ax.set_title(\"Group Principal Regression Coefficients (FA only)\", fontsize=18)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}