{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Load and interact with an AFQ dataset\n\nThis example loads AFQ data from CSV files and manipulates that data using\nscikit-learn transformers and estimators. First we fetch the Weston-Havens\ndataset described in Yeatman et al [1]_. This dataset contains tractometry\nfeatures from 77 subjects ages 6-50.\n\nNext, we split the dataset into a train and test split, impute missing values,\nand fit a LASSO model, all using :class:`AFQDataset` methods. Predictive\nperformance for the default LASSO model is abysmal. It is only used here to\ndemonstrate the use of scikit-learn estimators. In a research setting, one might\nuse more advanced estimators, such as the SGL [2]_, a gradient boosting machine,\nor a neural network.\n\nFinally, we convert the AFQDataset to a tensorflow dataset and fit a basic\none-dimensional CNN to predict age from the features. This last step requires that\nAFQ-Insight has been installed with::\n\n    pip install afqinsight[tf]\n\nor that tensorflow has been separately installed with::\n\n    pip install tensorflow\n\n.. [1]  Jason D. Yeatman, Brian A. Wandell, & Aviv A. Mezer, \"Lifespan\n    maturation and degeneration of human brain white matter\" Nature\n    Communications, vol. 5:1, pp. 4932, 2014 DOI: 10.1038/ncomms5932\n\n.. [2]  Adam Richie-Halford, Jason Yeatman, Noah Simon, and Ariel Rokem\n   \"Multidimensional analysis and detection of informative features in human\n   brain white matter\" PLOS Computational Biology, 2021 DOI:\n   10.1371/journal.pcbi.1009136\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import afqinsight.nn.tf_models as nn\nimport os.path as op\nimport tensorflow as tf\n\nfrom afqinsight.datasets import download_weston_havens\nfrom afqinsight import AFQDataset\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch example data\n\nThe :func:`download_weston_havens` function download the data used in this\nexample and places it in the `~/.cache/afq-insight/weston_havens` directory.\nIf the directory does not exist, it is created. The data follows the format\nexpected by the :func:`load_afq_data` function: a file called `nodes.csv` that\ncontains AFQ tract profiles and a file called `subjects.csv` that contains\ninformation about the subjects. The two files are linked through the\n`subjectID` column that should exist in both of them. For more information\nabout this format, see also the [AFQ-Browser documentation](https://yeatmanlab.github.io/AFQ-Browser/dataformat.html) (items 2 and 3).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "workdir = download_weston_havens()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Read in the data\n\nNext, we read in the data. The :func:`AFQDataset.from_files` static method\nexpects a the filenames of a nodes.csv and subjects.csv file, and returns a\ndataset object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = AFQDataset.from_files(\n    fn_nodes=op.join(workdir, \"nodes.csv\"),\n    fn_subjects=op.join(workdir, \"subjects.csv\"),\n    dwi_metrics=[\"md\", \"fa\"],\n    target_cols=[\"Age\"],\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train / test split\n\nWe can use the dataset in the :func:`train_test_split` function just as we\nwould with an array.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_train, dataset_test = train_test_split(dataset, test_size=1 / 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Impute missing values\n\nNext we train an imputer on the training set and use it to transform the\nfeatures in both the training and the test set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "imputer = dataset_train.model_fit(SimpleImputer(strategy=\"median\"))\ndataset_train = dataset_train.model_transform(imputer)\ndataset_test = dataset_test.model_transform(imputer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit a LASSO model\n\nNext we fit a LASSO estimator to the training data and print the score of that\nmodel on the test dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimator = dataset_train.model_fit(Lasso())\ny_pred = dataset_test.model_predict(estimator)\ntrain_score = dataset_train.model_score(estimator)\ntest_score = dataset_test.model_score(estimator)\nprint(\"LASSO train score:\", train_score)\nprint(\"LASSO test score: \", test_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert to tensorflow datasets\n\nNext we convert the train and test datasets to tensorflow datasets\nand use one of AFQ-Insight's built-in one-dimensional CNNs to predict\nage. This part of the example will only work if you have either installed\nAFQ-Insight with tensorflow using::\n\n    pip install afqinsight[tf]\n\nor separately install tensorflow using::\n\n    pip install tensorflow\n\nThis model also performs poorly. It turns out predicting age in\nthis dataset requires a bit more work.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tfset_train = dataset_train.as_tensorflow_dataset()\ntfset_test = dataset_test.as_tensorflow_dataset()\n\nbatch_size = 2\ntfset_train = tfset_train.batch(8)\ntfset_test = tfset_test.batch(8)\n\nprint(\"CNN Architecture\")\nmodel = nn.cnn_lenet(\n    input_shape=(100, 40), output_activation=None, n_classes=1, verbose=True\n)\n\nmodel.compile(\n    loss=\"mean_squared_error\",\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    metrics=[\"mean_squared_error\"],\n)\n\nmodel.fit(tfset_train, epochs=500, validation_data=tfset_test, verbose=0)\n\nprint()\nprint(\"CNN R^2 score: \", r2_score(dataset_test.y, model.predict(tfset_test)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}